---
title: "[졸업작품] AI 비문 인식 모델 개발기#2: 첫 번째 시도와 예상치 못한 벽"
date: 2025-08-14
permalink: /posts/2025/08/졸업작품-일지-2/
tags:
  - 졸업작품
  - AI
  - 처음엔 다 그래
 
---

안녕하세요\! 지난 포스트에서 저의 원대한 계획을 공유드렸었죠. 이번 포스트에서는 그 계획을 바탕으로 진행했던 첫 번째 구체적인 시도와, 그 과정에서 마주했던 예상치 못한 벽에 대해 솔직하게 이야기해 보려 합니다.

-----

### 첫 번째 계획: 기본에 충실하자

처음 저의 계획은 비교적 간단했습니다. 이미 성능이 검증된 기술들을 조합하여 기본 모델을 만드는 것이었죠.

#### **계획 1: 데이터 전처리**

우선, 모델이 비문의 미세한 특징을 잘 학습할 수 있도록 이미지 전처리 파이프라인을 구축했습니다. 단순히 이미지를 리사이징하고 정규화하는 것을 넘어, 비문의 질감과 주름 패턴을 강조하기 위해 **CLAHE(Contrast Limited Adaptive Histogram Equalization)와 Sharpening 기법**을 적용했습니다. 이는 이미지의 국소적인 대비를 높여 숨겨진 패턴을 드러내는 데 효과적인 방법입니다.

#### **계획 2: 아키텍처 구성**

모델 구조는 두 이미지의 유사도를 비교하는 데 특화된 \*\*샴 네트워크(Siamese Network)\*\*를 기반으로 했습니다. 두 개의 이미지를 동일한 가중치를 공유하는 네트워크에 통과시켜 각각의 특징 벡터를 추출하는 방식이죠. 백본으로는 가장 널리 쓰이고 안정적인 `ResNet50`을 선택했습니다.

학습을 위해서는 **대조 손실(Contrastive Loss)** 함수를 사용했습니다. 이 함수는 같은 강아지의 비문 쌍은 특징 공간에서 가깝게 만들고, 다른 강아지의 비문 쌍은 멀리 떨어뜨리도록 모델을 학습시킵니다.

-----

### 예상치 못한 벽: 실망스러운 결과

저는 이 모든 구현을 마치고 자신 있게 첫 번째 모델 훈련을 시작했습니다. 하지만 결과는 처참했습니다. 예상했던 것보다 성능이 훨씬 낮았고, 모델이 비문을 제대로 구별해내지 못했습니다.

단순히 좋은 부품들을 모은다고 해서 최고의 성능이 나오는 것은 아니었습니다. 저는 프로젝트의 첫 단계에서부터 커다란 벽에 부딪힌 기분이었습니다. 제가 구현한 코드 어딘가에 문제가 있는 건지, 아니면 이 접근법 자체가 잘못된 것인지, 모든 것이 불확실했습니다.

저는 처음부터 다시 시작해야만 했습니다. 도대체 무엇이 문제였을까요? 어떻게 해야 모델의 성능을 끌어올릴 수 있을까요?

-----