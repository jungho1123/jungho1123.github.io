---
title: "[졸업작품] AI 비문 인식 모델 개발기#4: 최종 성능 분석과 결론"
date: 2025-08-14
permalink: /posts/2025/08/졸업작품-일지-4/
tags:
  - 졸업작품
  - 개발일지
  - AI
  - PyTorch
  - 모델구현
  - 데이터증강
---

길고 길었던 개발 여정의 마지막 장입니다. 지난 포스트에서는 체계적인 Ablation Study를 통해 제가 직접 설계한 `SEResNeXt-IBN-Custom` 아키텍처의 우수성을 증명했습니다. 이번 포스트에서는 이 최종 모델을 현존하는 다른 강력한 모델과 비교한 최종 대결의 결과와, 이 프로젝트를 통해 얻은 결론을 공유하고자 합니다.

-----

### 최종 대결: SEResNeXt50-IBN-Custom vs. TF-EfficientNet-B4

저는 Ablation Study를 통해 검증된 최강의 조합을 50-layer 모델로 확장한 `SEResNeXt50-IBN-Custom`을 최종 모델로 선정했습니다. 그리고 이 모델의 성능을 객관적으로 평가하기 위해, 산업계에서 널리 인정받는 강력한 모델인 `TF-EfficientNet-B4`를 비교 대상으로 설정했습니다.

특히 저는 이번 최종 실험에서 **실제 서비스 환경을 시뮬레이션**하기 위한 중요한 조건을 추가했습니다. 학습 데이터에서 긍정 쌍(같은 강아지)과 부정 쌍(다른 강아지)의 비율을 **1:3으로 구성**한 것입니다. 이는 앱에 처음 비문을 등록하는 사용자(부정 쌍이 훨씬 많이 발생하는 시나리오)가 많을 것이라는 현실적인 가정에 기반한, 더 어렵고 까다로운 테스트 조건이었습니다.

-----

### 최종 결과: 신뢰성으로 증명된 승리

| Metric | **SEResNeXt50-IBN-Custom** | TF-EfficientNet-B4 |
| :--- | :---: | :---: |
| **Best F1 Score** | **0.9864** | 0.9741 |
| **ROC AUC** | **0.9995** | 0.9987 |
| **PR AUC** | **0.9984** | 0.9963 |
| **오분류 (FP)** | **100** | 188 |
| **오분류 (FN)** | **64** | 124 |

\<p style="text-align: center; font-size: 0.9em;"\>표 2. 주요 모델 성능 지표 비교 \</p\>

결과는 놀라웠습니다. F1 점수, ROC AUC 등 모든 주요 지표에서 제가 제안한 모델이 근소하게 우수한 성능을 보였습니다. 하지만 가장 주목해야 할 점은 **오분류 건수**입니다. 제 모델은 잘못된 비문을 맞다고 판단하는 **FP(False Positive)와, 맞는 비문을 틀리다고 판단하는 FN(False Negative)의 수가 비교 모델에 비해 현저히 적었습니다**. 이는 단순히 점수가 높은 것을 넘어, 실제 서비스 환경에서 사용자가 겪을 오류가 훨씬 적다는 것을 의미하며, 제 모델의 **높은 신뢰성**을 증명하는 결정적인 결과였습니다.

-----

### 결론: 긴 여정의 끝에서

첫 모델의 실패에서 시작해, 수많은 논문을 읽고 가설을 세우고, 세상에 없던 모델을 직접 만들고, 치열한 의심 끝에 스스로 그 성능을 증명해내기까지 정말 긴 여정이었습니다.

이번 프로젝트를 통해 저는 **IBN 모듈을 통한 외형 변화 강인성 확보**와 **SE 및 ResNeXt 구조를 통한 특징 표현력 강화**의 시너지가, 비문 인식이라는 까다로운 문제를 해결하는 최고의 열쇠였음을 증명할 수 있었습니다. 단순히 코드를 작성하는 것을 넘어, 문제를 정의하고 가설을 세우며 실험으로 증명하는 연구의 전 과정을 깊이 있게 경험할 수 있었던 소중한 시간이었습니다.

지금까지 저의 졸업작품 개발기를 함께해주셔서 진심으로 감사합니다\!