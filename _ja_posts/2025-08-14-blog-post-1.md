---
title: "[졸업작품] AI 비문 인식 모델 개발기 #1: 길을 찾아서 (Deep Dive)"
date: 2025-08-14
permalink: /posts/2025/08/졸업작품-일지-1/
tags:
  - 졸업작품
  - 개발일지
  - AI
  - 반려견 비문인식
  - Siamese Network
  - Contrastive Learning
---

안녕하세요! 동양미래대학교에서 인공지능을 공부하고 있는 학생입니다.

저희 팀은 이번 졸업작품으로 **'견주와 반려견을 위한 종합 펫케어 앱'**을 만들고 있습니다. 앱의 여러 기능 중 제가 맡은 파트는 바로 **AI를 이용해 강아지의 신원을 확인하는 '비문 인식' 모델 개발**입니다. 오늘은 이 모델의 방향성을 잡기까지, 제가 겪었던 수많은 우여곡절과 그 끝에서 발견한 한 줄기 빛에 대한 이야기를 공유하려 합니다.

### 첫 번째 난관: "이 데이터, 정말 써도 될까??"

가장 먼저 한 일은 역시 선행 연구 조성이었습니다. 다행히 GitHub에서 강아지 코를 찾아내는 객체 탐지(Object Detection) 프로젝트를 발견할 수 있었죠.

하지만 자세히 들여다보니 한 가지 큰 문제에 부딪혔습니다. 코를 '탐지'하는 부분은 괜찮았지만, 어떤 강아지인지 '인식'하는 모델은 저작권이 불분명한 지인의 반려견 이미지를 학습에 사용한 것을 확인했습니다.

'이걸 그대로 써도 될까?' 고민 끝에, 저희는 조금 돌아가더라도 더 안전하고 올바른 길을 택하기로 했습니다.

> **결론: 코 `탐지` 모델은 오픈소스를 활용하되, 핵심인 비문 `인식` 모델은 우리가 직접 만들자!**

### PART 1. 코는 어디에? 똑똑한 탐정, YOLOv5

일단 이미지에서 강아지의 코 영역을 정확히 찾아내야 합니다. 이 부분은 훌륭한 오픈소스인 **YOLOv5**를 활용한 기존 프로젝트를 참고했습니다.

> **🔗 참고 프로젝트**
> * **dognose_recognition_management_service:** [https://github.com/DI-LEE/dognose_recognition_management_service](https://github.com/DI-LEE/dognose_recognition_management_service)

이 프로젝트 덕분에 저희는 더 중요한 문제에 집중할 시간을 벌 수 있었습니다.

### PART 2. 그래서, 누구의 코? 치열했던 탐구의 시간

직접 만들기로 결심한 순간, 막막함이 밀려왔습니다. '어디서부터 시작해야 하지?' 그때, 구세주처럼 **'CVPR 2022 Pet Biometric Challenge'**라는 대회를 알게 되었고, 여기서 사용된 공개 데이터를 확보할 수 있었습니다.

> **🔗 데이터 출처**
> * **Pet Biometric Challenge 2022 (Kaggle):** [https://www.kaggle.com/datasets/zekunn/pet-biometric-challenge](https://www.kaggle.com/datasets/zekunn/pet-biometric-challenge)

이제 길은 명확해졌습니다. **"최고의 팀들은 어떻게 했을까?"**

단순히 참고하는 것에서 그치지 않았습니다. 저는 1등과 3등 팀의 GitHub 리포지토리를 모두 열어두고, 두 팀이 어떤 데이터 **증강(Augmentation) 기법**을 사용했는지 코드 라인 하나하나를 비교 분석했습니다. 코드뿐만 아니라, 두 팀이 발표한 **논문**까지 모두 찾아 읽으며 어떤 **백본(Backbone) 아키텍처**와 **손실 함수(Loss Function)**를 선택했는지, 그리고 그 근거는 무엇인지 밤새워 파고들었습니다.

> **🔗 참고한 프로젝트**
> * **CVPR 2022 Challenge 1등 팀 GitHub:** [https://github.com/dashengge/pet-biometrics](https://github.com/dashengge/pet-biometrics)
> * **CVPR 2022 Challenge 3등 팀 GitHub:** [https://github.com/muzishen/Pet-ReID-IMAG](https://github.com/muzishen/Pet-ReID-IMAG)

#### 한 줄기 빛: '샴 네트워크'와의 만남

그렇게 수많은 논문과 코드를 헤매던 중, 특히 1등 팀의 논문에서 제 눈을 사로잡은 아이디어가 있었습니다. 바로 **'샴 네트워크(Siamese Network)'**였습니다.



'샴 네트워크'는 쌍둥이(Siamese)라는 이름처럼, 두 개의 동일한 네트워크에 이미지를 각각 입력해 두 이미지의 특징이 얼마나 유사한지를 직접 비교하는 방식입니다. 단순히 '이건 A 강아지야'라고 분류하는 것을 넘어, **'이 비문과 저 비문이 같은 강아지의 것일 확률'**을 계산하는 거죠.

그 순간 머릿속에 번개가 치는 듯했습니다. ⚡

샴 네트워크의 아이디어에 **자기지도학습(Contrastive Learning)** 개념을 결합하고, **대조 손실(Contrastive Loss)** 함수를 사용한다면... 이건 정말 엄청난 결과를 낼 수 있겠다는 확신이 들었습니다. **비슷한 이미지는 가깝게(Pull), 다른 이미지는 멀게(Push) 만드는 이 조합**이야말로, 복잡한 비문 패턴에서 개체를 구별해 내는 핵심을 꿰뚫는 방법이라고 생각했습니다.

### 앞으로의 계획: 이제 진짜 시작

길고 긴 탐색 끝에, 드디어 우리가 나아갈 길을 명확하게 정의할 수 있게 되었습니다.

1.  **YOLOv5**로 이미지에서 코를 정확히 찾아내고,
2.  **Siamese Network 구조를 기반**으로 **Contrastive Learning**을 적용해, 우리만의 비문 인식 모델을 만든다!

물론, 이제부터가 진짜 시작입니다. 다음 포스팅에서는 이 아이디어를 실제로 구현하기 위해 **모델의 기초를 어떻게 설계했는지** 그 구체적인 과정을 공유해 드리겠습니다.