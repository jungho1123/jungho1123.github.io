---
title: "[졸업작품] AI 비문 인식 모델 개발기 #3: 최고의 조합을 찾아서"
date: 2025-08-14
permalink: /posts/2025/08/졸업작품-일지-3/
tags:
  - 졸업작품
  - 개발일지
  - AI
  - PyTorch
  - 모델구현
  - 데이터증강
---

지난 포스트에서 공유했듯, 저의 첫 번째 시도는 꽤나 뼈아픈 실패로 끝났습니다. 하지만 좌절은 새로운 탐구의 시작이었습니다. 이번 포스트에서는 그 실패를 딛고 일어서 '최고의 조합'을 찾아 나섰던 저의 가설 설정과 검증, 그리고 창조의 과정을 보여드리겠습니다.

-----

### 방황 속에서 발견한 가설

"도대체 뭐가 문제일까?" 저는 이 질문에 답하기 위해 수많은 논문을 다시 읽기 시작했습니다. 특히 'Res'로 시작하는 수많은 모델 아키텍처들을 보며 혼란에 빠지기도 했지만, 그 과정에서 몇 가지 핵심적인 기술들의 장점을 깊이 이해하게 되었습니다.

  * **Squeeze-and-Excitation (SE) 모듈**: 채널별 중요도를 학습해, 모델이 이미지의 핵심 특징에 더 집중하도록 돕는 기술입니다.
  * **Instance-Batch Normalization (IBN)**: IBN-Net 논문에 따르면, 이 기술은 Instance Normalization으로 조명이나 각도 같은 '외형' 변화에 강인함을 더하고, Batch Normalization으로 '내용' 정보를 보존하여 모델의 일반화 성능을 크게 향상시킵니다.
  * **ResNeXt**: 'Cardinality'라는 개념을 통해 더 풍부하고 다양한 특징을 학습할 수 있게 합니다.

이 기술들을 공부하며 머릿속에 하나의 가설이 떠올랐습니다. **"이 세 가지 기술을 모두 합친다면, 비문 인식이라는 까다로운 문제에 최적화된, 세상에 없는 최고의 모델을 만들 수 있지 않을까?"**

-----

### 없으면 만든다: SEResNeXt-IBN-Custom의 탄생

가설을 세우고 나니 자신감이 붙었습니다. 하지만 곧바로 또 다른 문제에 부딪혔습니다. 제가 구상한 **SE + IBN + ResNeXt 조합의 모델은 `timm`과 같은 기존 라이브러리에 존재하지 않았습니다.**

결국 저는 "없으면 직접 만든다"는 결심을 하고, `SEResNeXt-IBN-Custom`이라는 저만의 커스텀 백본을 처음부터 구현하기 시작했습니다. `backbone_build.py`로 실험 환경을 만들고, `seresnet_ibn_custom.py`에 제 모든 가설을 담아 코드를 작성했죠.

-----

### 의심에서 확신으로: 증명의 여정 (Ablation Study)

직접 만든 모델의 초기 테스트 결과는 놀라웠습니다. 하지만 문득 '이게 정말 내 실력일까? 그냥 운이 좋았던 건 아닐까?' 하는 과학자로서의 의구심이 들었습니다. 이 의문을 해소하기 위해, 저는 제 가설이 옳았음을 스스로 증명하는 \*\*Ablation Study(절제 연구)\*\*를 설계했습니다.

각 기술 요소(SE, IBN)를 하나씩 추가하고 제거해보며 성능 변화를 체계적으로 비교하는 실험이었습니다. 더 빠르고 공정한 비교를 위해, 비교적 가벼운 26-layer 모델들을 사용했습니다.

| Model Name | SE | IBN | F1 Score | ROC AUC |
| :--- | :-: | :-: | :--- | :--- |
| resnet26\_plain | X | X | 0.8865 | 0.9753 |
| resnet26\_ibn\_a | X | O | 0.9140 | 0.9874 |
| seresnet26\_plain | O | X | 0.9268 | 0.9888 |
| **seresnext26\_ibn\_custom** | **O** | **O** | **0.9305** | **0.9903** |

\<p style="text-align: center; font-size: 0.9em;"\>표 1. Ablation Study 결과 요약 \</p\>

결과는 명확했습니다. **IBN 모듈과 SE 모듈은 각각 독립적으로, 그리고 함께 사용되었을 때 비문 인식 성능에 긍정적인 영향을 미쳤습니다**. 특히 모든 기술을 결합한 `seresnext26_ibn_custom` 모델이 가장 우수한 성능을 기록하며, 저의 가설이 단순한 운이 아니었음을 증명해 주었습니다.

이제 저의 가설이 옳았음을 증명했습니다. 그렇다면 이 최강의 조합으로 만든 제 최종 모델은, 현존하는 다른 강력한 모델과 비교했을 때 어느 정도의 성능을 보여줄까요? 다음 포스트에서 그 최종 대결의 결과를 공개하겠습니다.

-----

```
```